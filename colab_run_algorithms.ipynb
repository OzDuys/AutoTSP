{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# AutoTSP: run non-synthetic datasets with 30s timeout on Colab\n",
    "\n",
    "This notebook clones the repo, installs dependencies, ingests the TSPLIB-style datasets in `Instance Datasets/datasets` into a JSONL problem file, and runs *all* algorithms with a 30 second per-instance timeout.\n",
    "\n",
    "> Notes: The ingest step can produce a large JSONL (hundreds of MB). You can cap the number of files (`LIMIT`) or skip very large instances (`MAX_CITIES`). If `pyconcorde` fails to build on Colab, rerun the install cell after enabling GPU or temporarily remove the Concorde solver from `SOLVER_SPECS`.\n",
    "\n",
    "Upload your prebuilt JSONL (e.g., /content/problems.jsonl) to skip the ingest cell; it will be used directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!rm -rf AutoTSP\n",
    "!git clone https://github.com/OzDuys/AutoTSP.git\n",
    "%cd AutoTSP\n",
    "!git status -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90353cda",
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (best-effort for pyconcorde)\n",
    "!python -m pip install --upgrade pip\n",
    "# Install everything except pyconcorde first (keeps failures from stopping the rest)\n",
    "!grep -v pyconcorde requirements.txt | python -m pip install -r /dev/stdin\n",
    "# Try to install pyconcorde; if it fails, we'll skip Concorde in the run step\n",
    "!python -m pip install git+https://github.com/jvkersch/pyconcorde || echo \"pyconcorde failed; Concorde solver will be skipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3c97d",
   "metadata": {
    "id": "params"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PROBLEMS = \"/content/problems.jsonl\"  # set to your uploaded full dataset JSONL\n",
    "RESULTS = \"Instance-Algorithm Datasets/Full Dataset/results_nonsynth_colab.jsonl\"\n",
    "TIME_LIMIT = 30.0  # seconds per algorithm per instance\n",
    "\n",
    "# Optional caps if you decide to regenerate instead of using the uploaded file. Set to \"\" to disable.\n",
    "LIMIT = \"\"       # e.g., 500 to ingest only first 500 files\n",
    "MAX_CITIES = \"\"  # e.g., 5000 to skip instances with >5000 cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d0403",
   "metadata": {
    "id": "ingest"
   },
   "outputs": [],
   "source": [
    "# Ingest TSPLIB-style datasets into JSONL (skips if the output file already exists)\n",
    "%%bash -s \"$PROBLEMS\" \"$LIMIT\" \"$MAX_CITIES\"\n",
    "PROBLEMS_PATH=\"$1\"\n",
    "LIMIT=\"$2\"\n",
    "MAX_CITIES=\"$3\"\n",
    "\n",
    "set -e\n",
    "if [ -f \"$PROBLEMS_PATH\" ]; then\n",
    "  echo \"Found $PROBLEMS_PATH; skipping ingest.\"\n",
    "  exit 0\n",
    "fi\n",
    "\n",
    "ARGS=(--root \"Instance Datasets/datasets\" --output \"$PROBLEMS_PATH\")\n",
    "if [ -n \"$LIMIT\" ]; then ARGS+=(--limit \"$LIMIT\"); fi\n",
    "if [ -n \"$MAX_CITIES\" ]; then ARGS+=(--max-cities \"$MAX_CITIES\"); fi\n",
    "\n",
    "python \"Instance Datasets/ingest_instances_from_datasets.py\" \"${ARGS[@]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed157b2d",
   "metadata": {
    "id": "run"
   },
   "outputs": [],
   "source": [
    "# Run algorithms with a 30s timeout per instance.\n",
    "# If pyconcorde failed to build, Concorde will be excluded automatically.\n",
    "%%bash -s \"$PROBLEMS\" \"$RESULTS\" \"$TIME_LIMIT\"\n",
    "PROBLEMS_PATH=\"$1\"\n",
    "RESULTS_PATH=\"$2\"\n",
    "TIME_LIMIT=\"$3\"\n",
    "\n",
    "set -e\n",
    "\n",
    "# Build algorithm list, dropping concorde_exact if pyconcorde is unavailable\n",
    "ALGOS=$(python - <<'PY'\n",
    "import importlib\n",
    "from AutoTSP import SOLVER_SPECS\n",
    "has_concorde = True\n",
    "try:\n",
    "    importlib.import_module(\"concorde\")\n",
    "except Exception:\n",
    "    has_concorde = False\n",
    "algos = []\n",
    "for name in SOLVER_SPECS:\n",
    "    if not has_concorde and name == \"concorde_exact\":\n",
    "        continue\n",
    "    algos.append(name)\n",
    "print(\" \".join(algos))\n",
    "PY\n",
    ")\n",
    "echo \"Running algorithms: $ALGOS\"\n",
    "\n",
    "python \"Instance-Algorithm Datasets/run_algorithms.py\" \\\n",
    "  --problems \"$PROBLEMS_PATH\" \\\n",
    "  --results \"$RESULTS_PATH\" \\\n",
    "  --time-limit \"$TIME_LIMIT\" \\\n",
    "  --algorithms $ALGOS \\\n",
    "  --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect"
   },
   "outputs": [],
   "source": [
    "# Inspect a few result rows\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "results_path = \"Instance-Algorithm Datasets/Full Dataset/results_nonsynth_colab.jsonl\"\n",
    "with open(results_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "    for row in islice(fh, 5):\n",
    "        print(json.loads(row))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_run_algorithms.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
